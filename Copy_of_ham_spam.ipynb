{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of ham_spam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeWAmVyWyKX7",
        "colab_type": "code",
        "outputId": "ab45e0d5-383c-4a2f-884e-ff1c956085a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct 31 10:00:43 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLbqQb2pK1zP",
        "colab_type": "text"
      },
      "source": [
        "Import the basic and important libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o323gRGkyNKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing important libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0R66dbW_VFpE",
        "colab_type": "code",
        "outputId": "3f6e1544-0abd-4f2c-c1aa-021ff0fa9939",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "from google.colab import files      #uploading json file from downloaded kaggle data json file\n",
        "files.upload()                      #Choose the kaggle.json file that you downloaded"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bf2bdc6a-a0e6-4cf8-b297-c873dcb6ba6e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-bf2bdc6a-a0e6-4cf8-b297-c873dcb6ba6e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"priyakashyap171\",\"key\":\"12e53bc8175a21a9912c575bdda18ac9\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F0RRJ3QUkF3",
        "colab_type": "code",
        "outputId": "e82b7de1-f20f-4f60-96d8-2efaf01e9cde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!mkdir -p ~/.kaggle                     #Make directory named kaggle and copy kaggle.json file there.\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json        #Change the permissions of the file.\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqyFe_IGMIaf",
        "colab_type": "code",
        "outputId": "b39eae38-fac3-4e7b-caae-5f454df74ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "ls                                      "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBx-gdqzMLH4",
        "colab_type": "code",
        "outputId": "217efddd-e27a-4829-bcbf-8de69331b353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd sample_data/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8iLDJ_BUu0j",
        "colab_type": "code",
        "outputId": "422dfc86-20e7-40cf-9080-912a70c6488a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "!ls -l ~/.kaggle\n",
        "!cat ~/.kaggle/kaggle.json"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4\n",
            "-rw------- 1 root root 71 Oct 31 10:02 kaggle.json\n",
            "{\"username\":\"priyakashyap171\",\"key\":\"12e53bc8175a21a9912c575bdda18ac9\"}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAWLJQ4nVUCa",
        "colab_type": "code",
        "outputId": "dfa03770-461c-401d-b7a2-07b871f2f50a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!pip install -q kaggle\n",
        "!pip install -q kaggle-cli"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.3MB 8.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 48.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 50.7MB/s \n",
            "\u001b[?25h  Building wheel for kaggle-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcJAL9zBVWtm",
        "colab_type": "code",
        "outputId": "7d2dd168-ae6d-453c-c64f-7910461d6d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "!kaggle datasets list #You can check if everything's okay by running this command.\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                      title                                               size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "tristan581/17k-apple-app-store-strategy-games            17K Mobile Strategy Games                            8MB  2019-08-26 08:22:16           8830  \n",
            "gustavomodelli/forest-fires-in-brazil                    Forest Fires in Brazil                              31KB  2019-08-24 16:09:16           9805  \n",
            "akhilv11/border-crossing-entry-data                      Border Crossing Entry Data                           4MB  2019-08-21 14:51:34           4126  \n",
            "rajeevw/ufcdata                                          UFC-Fight historical data from 1993 to 2019          3MB  2019-07-05 09:58:02           5171  \n",
            "shuyangli94/food-com-recipes-and-user-interactions       Food.com Recipes and Interactions                  267MB  2019-10-12 06:30:37           2872  \n",
            "chirin/africa-economic-banking-and-systemic-crisis-data  Africa Economic, Banking and Systemic Crisis Data   14KB  2019-07-21 02:00:17           3172  \n",
            "ruslankl/european-union-lgbt-survey-2012                 EU LGBT Survey                                     610KB  2019-07-19 11:15:25           1446  \n",
            "kapilverma/hindi-bible                                   Hindi Bible                                          4MB  2019-09-07 18:04:35            271  \n",
            "hmavrodiev/sofia-air-quality-dataset                     Sofia air quality dataset                            3GB  2019-09-14 05:48:09           1055  \n",
            "brkurzawa/us-breweries                                   US Breweries                                        76KB  2019-10-02 03:15:27           1287  \n",
            "jojoker/singapore-airbnb                                 Singapore Airbnb                                   350KB  2019-09-25 22:05:44           1476  \n",
            "srikantsahu/co2-and-ghg-emission-data                    CO2 and GHG emission data                           91KB  2019-09-26 20:10:59           1205  \n",
            "pascalbliem/european-social-survey-ess-8-ed21-201617     European Social Survey (ESS) 8 ed2.1 (2016/17)      10MB  2019-09-29 07:30:37            437  \n",
            "grikomsn/amazon-cell-phones-reviews                      Amazon Cell Phones Reviews                          10MB  2019-09-29 02:26:48           1702  \n",
            "irinachuchueva/russian-wholesale-electricity-market      Russian Wholesale Electricity Market                 1MB  2019-10-09 08:20:57            413  \n",
            "smid80/canadian-federal-election-results-timeseries      Canadian Federal Election Results (Timeseries)      18MB  2019-10-09 11:08:29            437  \n",
            "hmavrodiev/london-bike-sharing-dataset                   London bike sharing dataset                        165KB  2019-10-10 12:49:37           2053  \n",
            "nitinsss/military-expenditure-of-countries-19602019      Military Spending of Countries (1960-2019)          55KB  2019-10-10 12:17:37           1968  \n",
            "mabusalah/brent-oil-prices                               Brent Oil Prices                                    38KB  2019-10-14 12:31:05           1101  \n",
            "valentynsichkar/traffic-signs-preprocessed               Traffic Signs Preprocessed                            0B  2019-08-31 18:22:11            945  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkZsyxMfWI02",
        "colab_type": "code",
        "outputId": "5b4eb06d-898e-4e2f-ebbd-740b24907779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32manscombe.json\u001b[0m*                mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  \u001b[01;32mREADME.md\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr8PA_CVWrC1",
        "colab_type": "code",
        "outputId": "d8f7fdf1-292e-4d60-f4b1-176991d4ac55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"priyakashyap171\"\n",
        "os.environ['KAGGLE_KEY'] = \"12e53bc8175a21a9912c575bdda18ac9\"\n",
        "!kaggle datasets download -d vivekchutke/spam-ham-sms-dataset      #downloading dataset directly from kaggle "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading spam-ham-sms-dataset.zip to /content/sample_data\n",
            "\r  0% 0.00/207k [00:00<?, ?B/s]\n",
            "\r100% 207k/207k [00:00<00:00, 63.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzu-X_3dXn2b",
        "colab_type": "code",
        "outputId": "8dfae7a1-2000-4965-f6f9-e4870a144bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "!kaggle datasets list                                              #You can again check if dataset is there by running this command.\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                      title                                               size  lastUpdated          downloadCount  \n",
            "-------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  \n",
            "tristan581/17k-apple-app-store-strategy-games            17K Mobile Strategy Games                            8MB  2019-08-26 08:22:16           8830  \n",
            "gustavomodelli/forest-fires-in-brazil                    Forest Fires in Brazil                              31KB  2019-08-24 16:09:16           9805  \n",
            "akhilv11/border-crossing-entry-data                      Border Crossing Entry Data                           4MB  2019-08-21 14:51:34           4126  \n",
            "rajeevw/ufcdata                                          UFC-Fight historical data from 1993 to 2019          3MB  2019-07-05 09:58:02           5171  \n",
            "shuyangli94/food-com-recipes-and-user-interactions       Food.com Recipes and Interactions                  267MB  2019-10-12 06:30:37           2872  \n",
            "chirin/africa-economic-banking-and-systemic-crisis-data  Africa Economic, Banking and Systemic Crisis Data   14KB  2019-07-21 02:00:17           3172  \n",
            "ruslankl/european-union-lgbt-survey-2012                 EU LGBT Survey                                     610KB  2019-07-19 11:15:25           1446  \n",
            "kapilverma/hindi-bible                                   Hindi Bible                                          4MB  2019-09-07 18:04:35            271  \n",
            "hmavrodiev/sofia-air-quality-dataset                     Sofia air quality dataset                            3GB  2019-09-14 05:48:09           1055  \n",
            "brkurzawa/us-breweries                                   US Breweries                                        76KB  2019-10-02 03:15:27           1287  \n",
            "jojoker/singapore-airbnb                                 Singapore Airbnb                                   350KB  2019-09-25 22:05:44           1476  \n",
            "srikantsahu/co2-and-ghg-emission-data                    CO2 and GHG emission data                           91KB  2019-09-26 20:10:59           1205  \n",
            "pascalbliem/european-social-survey-ess-8-ed21-201617     European Social Survey (ESS) 8 ed2.1 (2016/17)      10MB  2019-09-29 07:30:37            437  \n",
            "grikomsn/amazon-cell-phones-reviews                      Amazon Cell Phones Reviews                          10MB  2019-09-29 02:26:48           1702  \n",
            "irinachuchueva/russian-wholesale-electricity-market      Russian Wholesale Electricity Market                 1MB  2019-10-09 08:20:57            413  \n",
            "smid80/canadian-federal-election-results-timeseries      Canadian Federal Election Results (Timeseries)      18MB  2019-10-09 11:08:29            437  \n",
            "hmavrodiev/london-bike-sharing-dataset                   London bike sharing dataset                        165KB  2019-10-10 12:49:37           2053  \n",
            "nitinsss/military-expenditure-of-countries-19602019      Military Spending of Countries (1960-2019)          55KB  2019-10-10 12:17:37           1968  \n",
            "mabusalah/brent-oil-prices                               Brent Oil Prices                                    38KB  2019-10-14 12:31:05           1101  \n",
            "valentynsichkar/traffic-signs-preprocessed               Traffic Signs Preprocessed                            0B  2019-08-31 18:22:11            945  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rwnRjMFNF7L",
        "colab_type": "code",
        "outputId": "5e3f831a-b73f-4683-8c4b-cee74055fee3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ls "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32manscombe.json\u001b[0m*                mnist_test.csv         spam-ham-sms-dataset.zip\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  \u001b[01;32mREADME.md\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUXOax9rPxbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "import zipfile\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lq_iC24Kn41",
        "colab_type": "text"
      },
      "source": [
        "Unzip the downloaded dataset zip file from kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec5YwssdPNRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "zip_ref = zipfile.ZipFile('spam-ham-sms-dataset.zip', \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWMqaLH8PnPj",
        "colab_type": "code",
        "outputId": "32603e82-3903-4c74-8234-754aa5a831aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;32manscombe.json\u001b[0m*                mnist_test.csv         sms_spam.csv\n",
            "california_housing_test.csv   mnist_train_small.csv  spam-ham-sms-dataset.zip\n",
            "california_housing_train.csv  \u001b[01;32mREADME.md\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0AjYtokQGCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "spam=pd.read_csv(\"sms_spam.csv\" ) #loading csv file to the dataframe named as spam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeBdYPgdUIRo",
        "colab_type": "code",
        "outputId": "0cf9177a-1127-465e-ae01-600ea39d06f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "spam.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Hope you are having a good week. Just checking in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>K..give back my thanks.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Am also doing in cbe only. But have to pay.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spam</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10,000 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                               text\n",
              "0   ham  Hope you are having a good week. Just checking in\n",
              "1   ham                            K..give back my thanks.\n",
              "2   ham        Am also doing in cbe only. But have to pay.\n",
              "3  spam  complimentary 4 STAR Ibiza Holiday or £10,000 ...\n",
              "4  spam  okmail: Dear Dave this is your final notice to..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ntQtX5YUKR_",
        "colab_type": "code",
        "outputId": "e1604e69-f729-4efc-d6a9-595020f2c73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK_Nv6NOIh5g",
        "colab_type": "text"
      },
      "source": [
        "**Removing Punctuation**\n",
        "\n",
        "This program removes all punctuations from a string. We will check each character of the string using for loop. If the character is a punctuation, empty string is assigned to it,i.e-'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFpjD7vvUPEe",
        "colab_type": "code",
        "outputId": "222e191b-4b10-4960-e913-abf85f538cea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "def remove_punct(text):                                #function which removes the punctuation from text\n",
        "  text_nopunct=\"\".join([char for char in text if char not in string.punctuation])\n",
        "  return text_nopunct\n",
        "spam['text_clean']=spam['text'].apply(lambda x: remove_punct(x))\n",
        "spam.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Hope you are having a good week. Just checking in</td>\n",
              "      <td>Hope you are having a good week Just checking in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>K..give back my thanks.</td>\n",
              "      <td>Kgive back my thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Am also doing in cbe only. But have to pay.</td>\n",
              "      <td>Am also doing in cbe only But have to pay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spam</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10,000 ...</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10000 c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
              "      <td>okmail Dear Dave this is your final notice to ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                         text_clean\n",
              "0   ham  ...   Hope you are having a good week Just checking in\n",
              "1   ham  ...                               Kgive back my thanks\n",
              "2   ham  ...          Am also doing in cbe only But have to pay\n",
              "3  spam  ...  complimentary 4 STAR Ibiza Holiday or £10000 c...\n",
              "4  spam  ...  okmail Dear Dave this is your final notice to ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AghbpZWTeSCW",
        "colab_type": "text"
      },
      "source": [
        "**Tokenizing**(Tokenizing separates text into units such as sentences or words.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adJ2KWC0eVgE",
        "colab_type": "code",
        "outputId": "b2d57376-c697-47ae-e309-235663b5202c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "import re                                             #tokenizing the data \n",
        "def tokenize(text):\n",
        "  tokens=re.split('\\W+',text)\n",
        "  return tokens\n",
        "spam['text_tkn']=spam['text_clean'].apply(lambda x:tokenize(x.lower()))\n",
        "spam.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_tkn</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Hope you are having a good week. Just checking in</td>\n",
              "      <td>Hope you are having a good week Just checking in</td>\n",
              "      <td>[hope, you, are, having, a, good, week, just, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>K..give back my thanks.</td>\n",
              "      <td>Kgive back my thanks</td>\n",
              "      <td>[kgive, back, my, thanks]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Am also doing in cbe only. But have to pay.</td>\n",
              "      <td>Am also doing in cbe only But have to pay</td>\n",
              "      <td>[am, also, doing, in, cbe, only, but, have, to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spam</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10,000 ...</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10000 c...</td>\n",
              "      <td>[complimentary, 4, star, ibiza, holiday, or, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
              "      <td>okmail Dear Dave this is your final notice to ...</td>\n",
              "      <td>[okmail, dear, dave, this, is, your, final, no...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                           text_tkn\n",
              "0   ham  ...  [hope, you, are, having, a, good, week, just, ...\n",
              "1   ham  ...                          [kgive, back, my, thanks]\n",
              "2   ham  ...  [am, also, doing, in, cbe, only, but, have, to...\n",
              "3  spam  ...  [complimentary, 4, star, ibiza, holiday, or, 1...\n",
              "4  spam  ...  [okmail, dear, dave, this, is, your, final, no...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P2WaW_iJvUV",
        "colab_type": "text"
      },
      "source": [
        "**Stop Words**:(Useless words (data)) A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8_bK2Rxn9PZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "5836d20b-de97-4517-96b4-fe1b7a5ef79b"
      },
      "source": [
        "nltk.download('stopwords')                                #download this only once"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3pM3TRnoBv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopword =nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMXeAWsBhwnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "95835b24-9060-4398-cbe2-18671439b908"
      },
      "source": [
        "def remove_stopwords(tokenized_list):                           # A function stop word is created which is commonly used word to remove (“the”, “a”, “an”, “in”)\n",
        "    text =[word for word in tokenized_list if word not in stopword]\n",
        "    return text\n",
        "  \n",
        "spam['text_nonstop']=spam['text_tkn'].apply(lambda x:remove_stopwords(x))\n",
        "spam.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_tkn</th>\n",
              "      <th>text_nonstop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Hope you are having a good week. Just checking in</td>\n",
              "      <td>Hope you are having a good week Just checking in</td>\n",
              "      <td>[hope, you, are, having, a, good, week, just, ...</td>\n",
              "      <td>[hope, good, week, checking]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>K..give back my thanks.</td>\n",
              "      <td>Kgive back my thanks</td>\n",
              "      <td>[kgive, back, my, thanks]</td>\n",
              "      <td>[kgive, back, thanks]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Am also doing in cbe only. But have to pay.</td>\n",
              "      <td>Am also doing in cbe only But have to pay</td>\n",
              "      <td>[am, also, doing, in, cbe, only, but, have, to...</td>\n",
              "      <td>[also, cbe, pay]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spam</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10,000 ...</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10000 c...</td>\n",
              "      <td>[complimentary, 4, star, ibiza, holiday, or, 1...</td>\n",
              "      <td>[complimentary, 4, star, ibiza, holiday, 10000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
              "      <td>okmail Dear Dave this is your final notice to ...</td>\n",
              "      <td>[okmail, dear, dave, this, is, your, final, no...</td>\n",
              "      <td>[okmail, dear, dave, final, notice, collect, 4...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                       text_nonstop\n",
              "0   ham  ...                       [hope, good, week, checking]\n",
              "1   ham  ...                              [kgive, back, thanks]\n",
              "2   ham  ...                                   [also, cbe, pay]\n",
              "3  spam  ...  [complimentary, 4, star, ibiza, holiday, 10000...\n",
              "4  spam  ...  [okmail, dear, dave, final, notice, collect, 4...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8mihEqOGuVj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Data preprocessing**\n",
        "\n",
        "**Stemmer**\n",
        "Producing morphological variants of a root/base word.\n",
        "for eg. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate”.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q70HPYoLnwZa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "684b26e8-5b71-4aeb-f73f-d90137956834"
      },
      "source": [
        "ps=nltk.PorterStemmer()\n",
        "\n",
        "def stemming(tokenized_text):\n",
        "  text=[ps.stem(word) for word in tokenized_text]\n",
        "  return text\n",
        "spam['text_stemmed']=spam['text_nonstop'].apply(lambda x:stemming(x))\n",
        "spam.head()\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_tkn</th>\n",
              "      <th>text_nonstop</th>\n",
              "      <th>text_stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Hope you are having a good week. Just checking in</td>\n",
              "      <td>Hope you are having a good week Just checking in</td>\n",
              "      <td>[hope, you, are, having, a, good, week, just, ...</td>\n",
              "      <td>[hope, good, week, checking]</td>\n",
              "      <td>[hope, good, week, check]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>K..give back my thanks.</td>\n",
              "      <td>Kgive back my thanks</td>\n",
              "      <td>[kgive, back, my, thanks]</td>\n",
              "      <td>[kgive, back, thanks]</td>\n",
              "      <td>[kgive, back, thank]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>Am also doing in cbe only. But have to pay.</td>\n",
              "      <td>Am also doing in cbe only But have to pay</td>\n",
              "      <td>[am, also, doing, in, cbe, only, but, have, to...</td>\n",
              "      <td>[also, cbe, pay]</td>\n",
              "      <td>[also, cbe, pay]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spam</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10,000 ...</td>\n",
              "      <td>complimentary 4 STAR Ibiza Holiday or £10000 c...</td>\n",
              "      <td>[complimentary, 4, star, ibiza, holiday, or, 1...</td>\n",
              "      <td>[complimentary, 4, star, ibiza, holiday, 10000...</td>\n",
              "      <td>[complimentari, 4, star, ibiza, holiday, 10000...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spam</td>\n",
              "      <td>okmail: Dear Dave this is your final notice to...</td>\n",
              "      <td>okmail Dear Dave this is your final notice to ...</td>\n",
              "      <td>[okmail, dear, dave, this, is, your, final, no...</td>\n",
              "      <td>[okmail, dear, dave, final, notice, collect, 4...</td>\n",
              "      <td>[okmail, dear, dave, final, notic, collect, 4,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                       text_stemmed\n",
              "0   ham  ...                          [hope, good, week, check]\n",
              "1   ham  ...                               [kgive, back, thank]\n",
              "2   ham  ...                                   [also, cbe, pay]\n",
              "3  spam  ...  [complimentari, 4, star, ibiza, holiday, 10000...\n",
              "4  spam  ...  [okmail, dear, dave, final, notic, collect, 4,...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdsY2V5x-5KF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "message_data_copy = spam['text_stemmed'].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_v-0lOIRz05",
        "colab_type": "text"
      },
      "source": [
        "Importing the libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1a81TyytBmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer #convert a collection of raw documents to a matrix of TF-IDF features\n",
        "from sklearn.model_selection import train_test_split        #split the dataset into the training and the testing datasets in various proportions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHNQhV0G91nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sp =\" \"\n",
        "li=[]\n",
        "final=\"\"\n",
        "for j in range(0,5559):\n",
        "  final=\"\"\n",
        "  for i in message_data_copy[j]:\n",
        "    final+= i\n",
        "    final+=sp\n",
        "  li.append(final)                                           #joing the tokenizing list and coverting then to a string                                            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1A6I7nDJIo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3cceffa7-026d-433f-ef2d-b4d6f055d7fe"
      },
      "source": [
        "len(li)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5559"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoyT1iHlJsHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.DataFrame(li ,columns =['Names'])                      #new dataframe which will read the whole sentence as a single string including  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e81bWWvlJ2DS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "c0afd3d1-7fd8-439a-d800-98daf62a0528"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hope good week check</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kgive back thank</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>also cbe pay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>complimentari 4 star ibiza holiday 10000 cash ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>okmail dear dave final notic collect 4 tenerif...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Names\n",
              "0                              hope good week check \n",
              "1                                  kgive back thank \n",
              "2                                      also cbe pay \n",
              "3  complimentari 4 star ibiza holiday 10000 cash ...\n",
              "4  okmail dear dave final notic collect 4 tenerif..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsyfqevPXahN",
        "colab_type": "text"
      },
      "source": [
        "### TfidfVectorizer\n",
        "**Term Frequency (TF)**\n",
        "The number of times a word appears in a document divided by the total number of words in the document. Every document has its own term frequency.\n",
        "\n",
        "**Inverse Data Frequency (IDF)**\n",
        "The log of the number of documents divided by the number of documents that contain the word ***w***. Inverse data frequency determines the weight of rare words across all documents in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re8X96JmKUb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "message_data_copy = df['Names'].copy()                        \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(\"english\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfUxffWs3cHV",
        "colab_type": "text"
      },
      "source": [
        "**string.translate**-To translate the characters in the string translate() is used to make the translations.\n",
        "\n",
        "**str.maketrans**-This function uses the translation mapping specified using the maketrans()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XY13A0-JRVh-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_preprocess(text):\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))        #i.e(ab,ef,a) will replace ab to ef and delete a from the string               \n",
        "    text = [word for word in text.split() if word.lower() not in stopwords.words('english')]      #if the splited word doesn't include stopwords join that words in string  \n",
        "    return \" \".join(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmRSZOm0LVZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "message_data_copy = message_data_copy.apply(text_preprocess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGS7VP_SLwyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9e52c034-1330-483c-894a-baf5566a3230"
      },
      "source": [
        "message_mat = vectorizer.fit_transform(message_data_copy)\n",
        "message_mat"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<5559x8005 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 46279 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLR0RUsMvOvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "message_train, message_test, spam_nospam_train, spam_nospam_test = train_test_split(message_mat, \n",
        "                                                        spam['type'], test_size=0.3, random_state=20)    #spliting the data into training and testing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq5asTQMB-bq",
        "colab_type": "text"
      },
      "source": [
        "**Logistic regression** function used at the core of the method,the logistic function(sigmoid function)   1 / (1 + e^-value)\n",
        "\n",
        "Below is an example logistic regression equation: \n",
        "y = e^(b0 + b1*x) / (1 + e^(b0 + b1*x)) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmXfmCsBvO96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "66a8bb62-4412-445b-9258-e1907d1daa4f"
      },
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score                                \n",
        "\n",
        "Spam_model = LogisticRegression(solver='liblinear',penalty='l1')               #applying logistic regression model \n",
        "Spam_model.fit(message_train, spam_nospam_train)                               \n",
        "pred = Spam_model.predict(message_test)                                        #predicting values based on model \n",
        "accuracy_score(spam_nospam_test,pred)                                          #accuracy score"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9538369304556354"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0PARjLavPEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "1030fd39-6717-46ea-c620-4207e6faab32"
      },
      "source": [
        "df['length'] = df['Names'].apply(len)\n",
        "df.head()                                                                       #measures the length of the string        "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Names</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hope good week check</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kgive back thank</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>also cbe pay</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>complimentari 4 star ibiza holiday 10000 cash ...</td>\n",
              "      <td>112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>okmail dear dave final notic collect 4 tenerif...</td>\n",
              "      <td>124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Names  length\n",
              "0                              hope good week check       21\n",
              "1                                  kgive back thank       17\n",
              "2                                      also cbe pay       13\n",
              "3  complimentari 4 star ibiza holiday 10000 cash ...     112\n",
              "4  okmail dear dave final notic collect 4 tenerif...     124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVWS0iN7vO7Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d02637db-56a4-4d56-d2e4-599c5bfebb30"
      },
      "source": [
        "\n",
        "length = df['length'].as_matrix()\n",
        "new_mat = np.hstack((message_mat.todense(),length[:, None])) #numpy.hstack() function is used to stack the sequence of input arrays\n",
        "                                                             # todense convert hstack in matrix form"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u54csm5JTv-F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0a051e73-3df7-4800-99a4-21ce01a23ae5"
      },
      "source": [
        "new_mat"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[  0.,   0.,   0., ...,   0.,   0.,  21.],\n",
              "        [  0.,   0.,   0., ...,   0.,   0.,  17.],\n",
              "        [  0.,   0.,   0., ...,   0.,   0.,  13.],\n",
              "        ...,\n",
              "        [  0.,   0.,   0., ...,   0.,   0., 105.],\n",
              "        [  0.,   0.,   0., ...,   0.,   0., 123.],\n",
              "        [  0.,   0.,   0., ...,   0.,   0.,  21.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8536OXZTv2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "message_train, message_test, spam_nospam_train, spam_nospam_test = train_test_split(new_mat, \n",
        "                                                        spam['type'], test_size=0.3, random_state=20)    #spliting the data into training and testing with matrix input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKzIe1pjWMY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5c647978-a403-4d5d-b98d-3c395c5de48a"
      },
      "source": [
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score                                \n",
        "\n",
        "Spam_model = LogisticRegression(solver='liblinear',penalty='l1')               #applying logistic regression model \n",
        "Spam_model.fit(message_train, spam_nospam_train)                               \n",
        "pred = Spam_model.predict(message_test)                                        #predicting values based on model \n",
        "accuracy_score(spam_nospam_test,pred)                                          #accuracy score"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9586330935251799"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCQ5ioDuWcFx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}